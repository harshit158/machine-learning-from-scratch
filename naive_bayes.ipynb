{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam', 'not spam']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha  # Smoothing parameter\n",
    "        self.class_counts = defaultdict(int)  # Counts of each class\n",
    "        self.feature_counts = defaultdict(lambda: defaultdict(int))  # Counts of feature occurrences per class\n",
    "        self.class_total_words = defaultdict(int)  # Total word count per class\n",
    "        self.vocabulary = set()  # Vocabulary across all documents\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Naive Bayes model according to X, y.\n",
    "        \"\"\"\n",
    "        for features, label in zip(X, y):\n",
    "            self.class_counts[label] += 1\n",
    "            for feature in features:\n",
    "                self.feature_counts[label][feature] += 1\n",
    "                self.class_total_words[label] += 1\n",
    "                self.vocabulary.add(feature)\n",
    "\n",
    "        # Calculate priors for each class\n",
    "        self.total_samples = len(y)\n",
    "        self.class_priors = {\n",
    "            c: count / self.total_samples for c, count in self.class_counts.items()\n",
    "        }\n",
    "\n",
    "    def _calculate_likelihood(self, feature, label):\n",
    "        \"\"\"\n",
    "        Calculate P(feature | label) with smoothing.\n",
    "        \"\"\"\n",
    "        feature_count = self.feature_counts[label].get(feature, 0)\n",
    "        total_words = self.class_total_words[label]\n",
    "        vocab_size = len(self.vocabulary)\n",
    "        return (feature_count + self.alpha) / (total_words + self.alpha * vocab_size) # IMPORTANT\n",
    "\n",
    "    def _calculate_log_posterior(self, features, label):\n",
    "        \"\"\"\n",
    "        Calculate the log posterior for a given class and document features.\n",
    "        \"\"\"\n",
    "        log_posterior = np.log(self.class_priors[label])\n",
    "        for feature in features:\n",
    "            log_posterior += np.log(self._calculate_likelihood(feature, label))\n",
    "        return log_posterior\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the provided data X.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for features in X:\n",
    "            posteriors = {\n",
    "                label: self._calculate_log_posterior(features, label)\n",
    "                for label in self.class_counts.keys()\n",
    "            }\n",
    "            predictions.append(max(posteriors, key=posteriors.get))\n",
    "        return predictions\n",
    "\n",
    "# Example Usage\n",
    "# Sample dataset\n",
    "X = [\n",
    "    [\"win\", \"lottery\", \"money\"],\n",
    "    [\"win\", \"prize\", \"money\"],\n",
    "    [\"hello\", \"how\", \"are\", \"you\"],\n",
    "    [\"hello\", \"meet\", \"me\"],\n",
    "]\n",
    "y = [\"spam\", \"spam\", \"not spam\", \"not spam\"]\n",
    "\n",
    "# Initialize, train and make predictions\n",
    "nb_classifier = NaiveBayesClassifier(alpha=1.0)\n",
    "nb_classifier.fit(X, y)\n",
    "predictions = nb_classifier.predict([[\"win\", \"money\"], [\"hello\", \"friend\"]])\n",
    "\n",
    "print(predictions)  # Output: ['spam', 'not spam']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
